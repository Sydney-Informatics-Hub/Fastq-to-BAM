#!/bin/bash

#########################################################
# 
# Platform: NCI Gadi HPC
# Description: merge recalibrated split BAM files into one final BAM
# per sample, parallelising tasks by sample
# Usage: first, run 'bash bqsr_merge_make_input.sh <cohort_name>'
# 	then run this script with 'qsub bqsr_merge_run_parallel.pbs'
# Details:
# 	Each sample has 3367 recalibrated BAM files to be merged into one 
# 	final BAM per sample. Process blood and tumour as separate jobs 
#	due to ~ double walltime requirement for tumour. This step can 
#	be performed with SAMbamba (this script) or GATK GatherBamFiles 
#	(see bqsr_merge_GATK_run_parallel). GATK is slower but costs less 
#	SUs. SAMbamba is faster but uses more SUs. For normal (30X) samples, 
#	request 24 CPU per sample and 4 GB per CPU, giving 24 threads
#	to SAMbamba. For tumour samples (60X) allow 48 CPU per sample and 
#	4 GB RAM per CPU, but still only provide 24 threads to SAMbamba.
#	If single tumour samples are run, the optimal setting is 36 CPU 
#	worth of RAM and 24 CPU SAMbamba threads, but this division is 
#	not possible with this parallel method. When the Broadwell nodes
# 	come online on Gadi, this script should be modified to use those
#	nodes as the RAM per CPU is perfect for merging. We have had issues
#	with SAMbamba after and Gadi downtime for system upgrades: SAMbamba
#	ceases to be able to merge so many files, and results in jobs that
#	hang idle (low CPU and MEM usage) indefinitely, producing no output. 
#	I suspect it's something to do with htslib but that's just a hunch.
#	A re-install of SAMbamba has so far worked. Need to investigate 
#	whether a containerised SAMbamba will be immune to these issues.
#	If you encounter this, kill the job (first wait at least half an hour 
#	as it can take some time for outputs to appear), re-install SAMbamba 
#	from source, and resubmit. If that fails, use the GATK method.   
# Author: Cali Willet
# cali.willet@sydney.edu.au
# Date last modified: 24/07/2020
#
# If you use this script towards a publication, please acknowledge the
# Sydney Informatics Hub (or co-authorship, where appropriate).
#
# Suggested acknowledgement:
# The authors acknowledge the scientific and technical assistance 
# <or e.g. bioinformatics assistance of <PERSON>> of Sydney Informatics
# Hub and resources and services from the National Computational 
# Infrastructure (NCI), which is supported by the Australian Government
# with access facilitated by the University of Sydney.
# 
#########################################################

#PBS -P <project>
#PBS -N bqsr-m-tumour
#PBS -l walltime=02:00:00
#PBS -l ncpus=480
#PBS -l mem=19000GB
#PBS -W umask=022
#PBS -q hugemem
#PBS -l wd
#PBS -o ./Logs/bqsr_merge-tumour.o
#PBS -e ./Logs/bqsr_merge-tumour.e
#PBS -lstorage=scratch/<project>

module load openmpi/4.0.2
module load nci-parallel/1.0.0


set -e

SCRIPT=./bqsr_merge_SAMbamba.sh 
INPUTS=./Inputs/bqsr_merge.input-tumour  

NCPUS=48 # NCPUS per task. Set to 48 for tumour, 24 for normal.

mkdir -p ./Final_bams ./Logs/BQSR_merge B./Error_capture/BQSR_merge


#########################################################
# Do not edit below this line  
#########################################################

CPN=48 #CPUs per node 
M=$(( CPN / NCPUS )) #tasks per node

sed "s|^|${SCRIPT} |" ${INPUTS} > ${PBS_JOBFS}/input-file

mpirun --np $((M * PBS_NCPUS / CPN)) \
        --map-by node:PE=${NCPUS} \
        nci-parallel \
        --verbose \
        --input-file ${PBS_JOBFS}/input-file
